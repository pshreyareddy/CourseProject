{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ProjectCodeForBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kDNPpAMV2RBOsX00bXTrJ35wxS6LIVoL",
      "authorship_tag": "ABX9TyPhQxpIzUGQOSnzXor2+ek1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pshreyareddy/CourseProject/blob/main/ProjectCodeForBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uv6HfU0Boze"
      },
      "source": [
        "Sarcasm Classification In Tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztfX6a25IihD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f268014-a52e-486d-f878-deabdfa209e3"
      },
      "source": [
        "# Install TensorFlow packages\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-addons\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 22kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.6MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.33.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=3c52cfededb30f8879369517e31cab2f39fd889482414d8ae0c759db5c81bd4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 10.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8PFP00GFakF",
        "outputId": "5e7f1307-7cf2-4051-a8eb-03805377c36b"
      },
      "source": [
        "!pip install ipython-autotime\n",
        " \n",
        "%load_ext autotime"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/58/a4a65efcce5c81a67b6893ade862736de355a3a718af5533d30c991831ce/ipython_autotime-0.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (50.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.2.0\n",
            "time: 125 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_N2xH-VY89K"
      },
      "source": [
        "Import Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10VItUvEvppl",
        "outputId": "2261018a-30be-4bd8-ade1-f695e15f9f61"
      },
      "source": [
        "import tensorflow as tf; \n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "time: 2.45 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeH4xKYdAFDu",
        "outputId": "9c6a3cc3-0a81-4b71-e136-328877456091"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "time: 161 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmUL_2tlKxOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a16f36-488f-44c2-af34-c641164e5ad9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import tensorflow packages\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,concatenate,Dense,GlobalAveragePooling1D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.05 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymgw8JqtZBww"
      },
      "source": [
        "Read Train Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfy5ui7YK7p7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70d122a-245e-4643-e84b-8fbc3d445e96"
      },
      "source": [
        "\n",
        "train = pd.read_json('https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/train.jsonl',lines=True)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 417 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf1pQ4U_ZHTj"
      },
      "source": [
        "Check train data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3F89UFPLFeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "eb350f83-c693-424b-a62e-fc33db40659b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
              "      <td>[A minor child deserves privacy and should be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
              "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [A minor child deserves privacy and should be ...\n",
              "1  SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n",
              "2  SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n",
              "3  SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n",
              "4  SARCASM  ...  [Man ... y ’ all gone “ both sides ” the apoca...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "stream",
          "text": [
            "time: 19.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i7z_zmjBCWH",
        "outputId": "5623204c-ec68-4eab-b8b4-855020bfba5c"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label       object\n",
              "response    object\n",
              "context     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.99 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD9GO_AiZWCH"
      },
      "source": [
        "Clean the response column in train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trL6cio9LMpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2f5ba7-e4b7-42d9-b9a3-f05c00eec065"
      },
      "source": [
        "#Removing @USER\n",
        "train['response']=train['response'].str.replace('@USER', \"\") \n",
        "#Removing <URL>\n",
        "train['response']=train['response'].str.replace('<URL>', \"\") \n",
        "#Removing 1ormore digits(range 0-9)\n",
        "train['response']=train['response'].str.replace('\\d+', '')\n",
        "#Converting to lower case\n",
        "train['response']=train['response'].str.lower()\n",
        "\n",
        "train['response']=train['response'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 74.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHZNtFazZbgp"
      },
      "source": [
        "Check the train data after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1W0r7b7pR_c6",
        "outputId": "11b52203-7e7c-47c4-a6bc-42946092a236"
      },
      "source": [
        "train['response'][0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   i dont get this  obviously you do care or you wouldve moved right along  instead you decided to care and troll her '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "text": [
            "time: 7.59 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAr4ENChLQYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d364e3-c181-4d1b-b6a2-93612c9e186d"
      },
      "source": [
        "train['response'].head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       i dont get this  obviously you do care or y...\n",
              "1      trying to protest about  talking about him a...\n",
              "2       he makes an insane about of money from the ...\n",
              "3      meanwhile trump wont even release his sat sc...\n",
              "4      pretty sure the antilincoln crowd claimed th...\n",
              "Name: response, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "text": [
            "time: 9.57 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgsrQktXZgzs"
      },
      "source": [
        "Convert context(list) into a string and apply the same cleaning logic added on response column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmEd6vJuLTa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49991999-d1f2-4180-a3e7-4bf0dd0ff15e"
      },
      "source": [
        "train['context']=train['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "train['context']=train['context'].str.replace('@USER', \"\") \n",
        "train['context']=train['context'].str.replace('<URL>', \"\") \n",
        "train['context']=train['context'].str.lower()\n",
        "train['context']=train['context'].str.replace('[^\\w\\s]','')\n",
        "train['context']=train['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 189 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w20XN-wXZ8X2"
      },
      "source": [
        "Check the train data after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "nOf-B5EFR18-",
        "outputId": "dd89e59a-72b2-4619-e12f-efe4e5932a74"
      },
      "source": [
        "train['context'][0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a minor child deserves privacy and should be kept out of politics  pamela karlan  you should be ashamed of your very angry and obviously biased public pandering  and using a child to do it  if your child isnt named barron  bebest melania couldnt care less  fact  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.47 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3a2UQTLWPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea0b4b2-4dfc-431c-b5b9-eef55524556e"
      },
      "source": [
        "train['context'].head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    a minor child deserves privacy and should be k...\n",
              "1      why is he a loser  hes just a press secretar...\n",
              "2    donald j  trump is guilty as charged  the evid...\n",
              "3    jamie raskin tanked doug collins  collins look...\n",
              "4    man  y  all gone  both sides  the apocalypse o...\n",
              "Name: context, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2gEhUXYaN3g"
      },
      "source": [
        "Check the length of train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhGnyAZRLY8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dae229a-3977-4d1f-c227-22b2d1f0d8e9"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.09 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvbob0xuaTD0"
      },
      "source": [
        "Check the class count of target variable 'label' (Balanced dataset with equal composition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy8ZYwoILctO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88734bb0-5458-42f7-b47c-665471be296f"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(train['label'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOT_SARCASM': 2500, 'SARCASM': 2500})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "stream",
          "text": [
            "time: 6.19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hNYeasPan5K"
      },
      "source": [
        "Label encode class variable to 0 and 1 from  NOT_SARCASM and SARCASM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDPBCmQLfcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab431cd7-b244-4ab2-e576-b42c68cb107d"
      },
      "source": [
        "le=LabelEncoder()\n",
        "train_label=le.fit_transform(train['label'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.52 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zhEdu4FbH9L"
      },
      "source": [
        "Read test data set and check the first 5 rows "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3y24FiDLg0Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0894375a-ba90-4a26-becb-a34f8d725907"
      },
      "source": [
        "\n",
        "test = pd.read_json('https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/test.jsonl',lines=True)\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
              "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
              "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@USER @USER @USER The irony being that he even...</td>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            context\n",
              "0  twitter_1  ...  [Well now that ’ s problematic AF <URL>, @USER...\n",
              "1  twitter_2  ...  [Last week the Fake News said that a section o...\n",
              "2  twitter_3  ...  [@USER Let ’ s Aplaud Brett When he deserves i...\n",
              "3  twitter_4  ...  [Women generally hate this president . What's ...\n",
              "4  twitter_5  ...  [Dear media Remoaners , you excitedly sharing ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "stream",
          "text": [
            "time: 300 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUADHO76BwO1",
        "outputId": "e2ee6c4c-ae80-4e16-bfa0-f8d23d08a8b2"
      },
      "source": [
        "test.dtypes"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          object\n",
              "response    object\n",
              "context     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.66 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gBKutXAbUzu"
      },
      "source": [
        "Apply the same cleaning logic for response and context columns in test  as done earlier on train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvD2Gsb9LnCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a7c582-178b-47db-a9d9-1b23099d682b"
      },
      "source": [
        "test['response']=test['response'].str.replace('@USER', \"\") \n",
        "test['response']=test['response'].str.replace('<URL>', \"\") \n",
        "test['response']=test['response'].str.replace('\\d+', '')\n",
        "test['response']=test['response'].str.lower()\n",
        "test['response']=test['response'].str.replace('[^\\w\\s]','')\n",
        "test['context']=test['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "test['context']=test['context'].str.replace('@USER', \"\") \n",
        "test['context']=test['context'].str.replace('<URL>', \"\") \n",
        "test['context']=test['context'].str.lower()\n",
        "test['context']=test['context'].str.replace('[^\\w\\s]','')\n",
        "test['context']=test['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 98.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsWaIP9Ybd9m"
      },
      "source": [
        "Check the test rows after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "QJzjkKLFSNvF",
        "outputId": "91120a69-e685-49b6-bdfd-0800c90176c0"
      },
      "source": [
        "test['response'][0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   my  year old  that just finished reading nietzsche and then asked me   ayo papa why these people always trying to cancel someone on twitter  trying to pretend like that makes them better themselves    to which i replied  idk   and he just  cuz hoes mad   im so proud  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.27 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZqTh3yc_SUax",
        "outputId": "0a90928b-9cd4-4dc4-e9d0-f0b4c84b3096"
      },
      "source": [
        "test['context'][0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'well now that  s problematic af   my  year old  asked me why they are making fun of native americans    i will take shit that didnt happen for     no  he actually in the gifted program and reads on second grade level    and he knows kansas city is in missouri'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.56 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNpSKL8LrIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "758cc967-81fb-4c9e-91fe-2b03b0d598b0"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>my  year old  that just finished reading ni...</td>\n",
              "      <td>well now that  s problematic af   my  year old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>how many verifiable lies has he told now   d...</td>\n",
              "      <td>last week the fake news said that a section of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>maybe docs just a scrub of a coach  i mean ...</td>\n",
              "      <td>let  s aplaud brett when he deserves it he co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>is just a cover up for the real hate inside ...</td>\n",
              "      <td>women generally hate this president  whats up ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>the irony being that he even has to ask why</td>\n",
              "      <td>dear media remoaners  you excitedly sharing cl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            context\n",
              "0  twitter_1  ...  well now that  s problematic af   my  year old...\n",
              "1  twitter_2  ...  last week the fake news said that a section of...\n",
              "2  twitter_3  ...   let  s aplaud brett when he deserves it he co...\n",
              "3  twitter_4  ...  women generally hate this president  whats up ...\n",
              "4  twitter_5  ...  dear media remoaners  you excitedly sharing cl...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "stream",
          "text": [
            "time: 21.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5qtdd7ZblWQ"
      },
      "source": [
        "Check the train rows after changes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC0yfGKeL_hZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0665e580-28af-4b72-b2e4-bcc34e887ee5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont get this  obviously you do care or y...</td>\n",
              "      <td>a minor child deserves privacy and should be k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>trying to protest about  talking about him a...</td>\n",
              "      <td>why is he a loser  hes just a press secretar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>he makes an insane about of money from the ...</td>\n",
              "      <td>donald j  trump is guilty as charged  the evid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>meanwhile trump wont even release his sat sc...</td>\n",
              "      <td>jamie raskin tanked doug collins  collins look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>pretty sure the antilincoln crowd claimed th...</td>\n",
              "      <td>man  y  all gone  both sides  the apocalypse o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  a minor child deserves privacy and should be k...\n",
              "1  SARCASM  ...    why is he a loser  hes just a press secretar...\n",
              "2  SARCASM  ...  donald j  trump is guilty as charged  the evid...\n",
              "3  SARCASM  ...  jamie raskin tanked doug collins  collins look...\n",
              "4  SARCASM  ...  man  y  all gone  both sides  the apocalypse o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "stream",
          "text": [
            "time: 20.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isO7qfb3btTd"
      },
      "source": [
        "Create a variable traindata from train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy7GjbYpM8SP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f43f52-a6a2-424e-a9cf-6a358671980f"
      },
      "source": [
        "traindata = train"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.01 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPz3I66NqCn",
        "outputId": "f562f090-a3f2-43b3-d6b7-68018a2a1c8e"
      },
      "source": [
        "len(train_label)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.53 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wimsQCqbyLI"
      },
      "source": [
        "Train Validation Split (To train on 4000 samples and validate on 1000 samples)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyiQgR3fLjHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f98ba85-346e-43c7-b687-4cb036d6d5c1"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(traindata.drop(labels=['label'], axis=1), train_label, test_size=0.2, random_state=42 ,stratify=train_label)\n",
        "#\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 15.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKTWWQUbOAyR",
        "outputId": "505d08cc-3ce8-49e7-f08e-d5bc99610508"
      },
      "source": [
        "X_train.shape   #Check the shape of X_train"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.27 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQ9BCQYOPbB",
        "outputId": "744b75d9-2235-4cea-8941-e592d5fb43d6"
      },
      "source": [
        "y_train.shape  #Check the shape of y_train\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.75 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWDjNnTTOXkV",
        "outputId": "fb98073c-a3bb-4714-b15c-562f39f18bf0"
      },
      "source": [
        " X_val.shape   #Check the shape of X_val"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2.93 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYV3l550cugd"
      },
      "source": [
        "Check the target variable balance in training and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdASYPQ4acDn",
        "outputId": "024299ee-982a-48dc-bf90-a2c7d0d922a1"
      },
      "source": [
        "print(Counter(y_val))  \n",
        "print(Counter(y_train))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 500, 1: 500})\n",
            "Counter({1: 2000, 0: 2000})\n",
            "time: 3.52 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpCBMZ_9wb-Q"
      },
      "source": [
        "Added a keras bert layer using bert uncased L-12_H-768_A-12. Tokenization approach using bert fulltokenizer followed as per usage in below tfhub link\n",
        "\n",
        "https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w5IQ1yaCJ5l",
        "outputId": "474163c7-d3fa-46da-8dae-b1645e50240c"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "hub"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow_hub' from '/usr/local/lib/python3.6/dist-packages/tensorflow_hub/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKpdfByIMMAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98fd1e2-b778-4ae4-d5d7-e56530e8f165"
      },
      "source": [
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "595wfOWl8jcP"
      },
      "source": [
        "\n",
        "Download and import bert tokenization file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPUMH0SbNNax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90eb69fc-91d4-4edc-a65e-cd9a0e4815f2"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 378 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbeqeDuNMUfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aa1d7e-71bf-4a09-cad4-c194473b5c9f"
      },
      "source": [
        "import tokenization\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 596 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcBJa14Lwr3K"
      },
      "source": [
        "Encoding function to separate the text into tokens,masks and segments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozqUNSBMTLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ea5e38-46e6-49ef-958e-6fe20b255c8e"
      },
      "source": [
        "# Reference link for encoder function:\n",
        "# https://www.analyticsvidhya.com/blog/2020/10/simple-text-multi-classification-task-using-keras-bert/\n",
        "def encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 14.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJbN9glMXG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2beb94d0-56bd-4c2d-813e-941f554904cd"
      },
      "source": [
        " max_len=256"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 723 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPCW5GNGOhVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e624045b-2e60-4b56-ac03-d45a0edaf818"
      },
      "source": [
        "val_response = encode(X_val.response, tokenizer, max_len=max_len)\n",
        "val_context = encode(X_val.context, tokenizer, max_len=max_len)\n",
        "val_labels=y_val"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCMviZPVMZde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81ea211-4f36-44bb-b2f4-6bd8f4744097"
      },
      "source": [
        "train_response = encode(X_train.response, tokenizer, max_len=max_len)\n",
        "train_context = encode(X_train.context, tokenizer, max_len=max_len)\n",
        "train_labels=y_train\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9TJBJ8McXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473aee9a-bbe4-4b69-d878-7f7f698f40cc"
      },
      "source": [
        "test_response = encode(test.response, tokenizer, max_len=max_len)\n",
        "test_context = encode(test.context, tokenizer, max_len=max_len)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkB-cvwWveNP"
      },
      "source": [
        "Set test_input "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmXxWlaRMeya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fc995e-8486-457f-a3bd-c272cd06478c"
      },
      "source": [
        "test_input=[test_context[0],test_context[1],test_context[2],test_response[0],test_response[1],test_response[2]]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.47 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPJG2p4uvH-9"
      },
      "source": [
        "Helper functions for Evaluation metrics like recall,precision and f1 score from\n",
        "https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So_tGeaJQRdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bfe9a9-e4b6-4c16-9595-6a00a9e7401b"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.75 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFYjwXSmd4Xy"
      },
      "source": [
        "Build Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiXHWqnMlQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb6e608-9257-4a24-e912-9c2d62cd7ab3"
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    \n",
        "    \n",
        "    # input word ids,masks,segment ids for context\n",
        "    # Refered to https://www.analyticsvidhya.com/blog/2020/10/simple-text-multi-classification-task-using-keras-bert/\n",
        "    context_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"context_word_ids\")\n",
        "    context_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"context_mask\")\n",
        "    context_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"context_seg_ids\")\n",
        "    context_pooled_output , context_seq_output = bert_layer([context_word_ids, context_mask, context_seg_ids])\n",
        "    context_clf_output = context_seq_output[:, 0, :]\n",
        "\n",
        "    # input word ids,masks,segment ids for response\n",
        "    reponse_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_word_ids\")\n",
        "    reponse_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_mask\")\n",
        "    reponse_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_seg_ids\")\n",
        "    response_pooled_output , reponse_seq_output = bert_layer([reponse_word_ids, reponse_mask, reponse_seg_ids])\n",
        "    reponse_clf_output = reponse_seq_output[:, 0, :]\n",
        "\n",
        "    #concatenation layer of outputs of bert layer for context and response\n",
        "    conclayer=concatenate([context_clf_output,reponse_clf_output])\n",
        "    # give conclayer as input to a simple dense network with 1 neuron with activation function sigmoid\n",
        "    out = Dense(1, activation='sigmoid')(conclayer)\n",
        "    \n",
        "    #set keras model with inputs as an array of context and response input word ids,mask and segment ids\n",
        "    model = Model(inputs=[context_word_ids, context_mask, context_seg_ids,reponse_word_ids,reponse_mask,reponse_seg_ids], outputs=out)\n",
        "    \n",
        "    #Model compilation\n",
        "    #Used adam optimizer with learning rate 1e-6, used binary cross entropy loss as its a binary classification problem\n",
        "    #Calculating accuracy,f1,precision and recall metrics for each run\n",
        "    model.compile(Adam(1e-6), loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 20 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66aMRVji68sg"
      },
      "source": [
        "Check summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouDt9OpzHBRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57849523-394b-480f-d1d6-f0628a67ded0"
      },
      "source": [
        "\n",
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "context_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)      [(None, 768), (None, 109482241   context_word_ids[0][0]           \n",
            "                                                                 context_mask[0][0]               \n",
            "                                                                 context_seg_ids[0][0]            \n",
            "                                                                 reponse_word_ids[0][0]           \n",
            "                                                                 reponse_mask[0][0]               \n",
            "                                                                 reponse_seg_ids[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 768)]        0           keras_layer_1[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           keras_layer_1[1][1]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1536)         0           tf_op_layer_strided_slice[0][0]  \n",
            "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1537        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,777\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "time: 2.64 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jXoYzrLd_FI"
      },
      "source": [
        "Set train_input (Array of train_context and train_reponse with inturn contains input word ids,mask and segment ids )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP2rqQdeMn7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96a6d3b-eec5-4726-cd51-97ab84ec466c"
      },
      "source": [
        "train_input=[train_context[0],train_context[1],train_context[2],train_response[0],train_response[1],train_response[2]]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.06 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kH5hXOU547s"
      },
      "source": [
        "\n",
        "Set val_input (Array of val_context and val_reponse with inturn contains input word ids,mask and segment ids )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnPSQ4UPPVL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83322936-cd07-4c31-e48a-04de0a348fc9"
      },
      "source": [
        "val_input=[val_context[0],val_context[1],val_context[2],val_response[0],val_response[1],val_response[2]]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.05 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H53q_MYh9zPD"
      },
      "source": [
        "Training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIa8suJBPnhX",
        "outputId": "7687a47d-6094-4afd-bd5a-150897e635cd"
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_input, y_train,\n",
        "    validation_data =(val_input,y_val),\n",
        "    epochs=3,\n",
        "    batch_size=3)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/3\n",
            "4000/4000 [==============================] - 346s 87ms/sample - loss: 0.5775 - acc: 0.6835 - f1_m: 0.5654 - precision_m: 0.5852 - recall_m: 0.6027 - val_loss: 0.5129 - val_acc: 0.7520 - val_f1_m: 0.6804 - val_precision_m: 0.6467 - val_recall_m: 0.7725\n",
            "Epoch 2/3\n",
            "4000/4000 [==============================] - 317s 79ms/sample - loss: 0.4321 - acc: 0.7968 - f1_m: 0.6888 - precision_m: 0.6932 - recall_m: 0.7341 - val_loss: 0.4604 - val_acc: 0.7860 - val_f1_m: 0.6856 - val_precision_m: 0.6707 - val_recall_m: 0.7495\n",
            "Epoch 3/3\n",
            "4000/4000 [==============================] - 317s 79ms/sample - loss: 0.3342 - acc: 0.8575 - f1_m: 0.7505 - precision_m: 0.7527 - recall_m: 0.7834 - val_loss: 0.4556 - val_acc: 0.7930 - val_f1_m: 0.6936 - val_precision_m: 0.6796 - val_recall_m: 0.7540\n",
            "time: 16min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mRDehi981H"
      },
      "source": [
        "Predictions for test_input for the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ayRkJGMxpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2aa88be-5978-4c32-848c-3779511dc8b5"
      },
      "source": [
        "pred=model.predict(test_input,verbose=1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1800/1800 [==============================] - 36s 20ms/sample\n",
            "time: 36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqzRrUPH-Bmz"
      },
      "source": [
        "Write the predictions for test dataset into answer.txt with columns id and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5oatnx-M3LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d9872f-587d-4efc-ca88-a58c925bb31a"
      },
      "source": [
        "\n",
        "sub=pred.round()\n",
        "sub=le.inverse_transform(sub.ravel().astype('int16'))\n",
        "sub=pd.DataFrame(sub,columns=['label'])\n",
        "sub=pd.concat([test['id'], sub], axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('answer.txt',sep=',',index=False,header=None)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 14.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCjEO6Mk-_Ci"
      },
      "source": [
        "Save model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-fkc9Xq-8xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c365735f-0955-4118-df0b-a0ad22b22e60"
      },
      "source": [
        "# model_save_name = 'bert_weights3.h5'\n",
        "# path = F\"/content/drive/My Drive/BertModelWeights/{model_save_name}\" \n",
        "# model.save_weights(path)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w-AsWVZ-Qxu"
      },
      "source": [
        "Loading model weights from already generated saved model weights file after training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2xuVMO1-d1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a1517f-44ea-4422-dc1e-b8dfd72861c5"
      },
      "source": [
        "model2 = build_model(bert_layer, max_len=max_len)\n",
        "model2.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "context_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)      [(None, 768), (None, 109482241   context_word_ids[0][0]           \n",
            "                                                                 context_mask[0][0]               \n",
            "                                                                 context_seg_ids[0][0]            \n",
            "                                                                 reponse_word_ids[0][0]           \n",
            "                                                                 reponse_mask[0][0]               \n",
            "                                                                 reponse_seg_ids[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 768)]        0           keras_layer_1[2][1]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 768)]        0           keras_layer_1[3][1]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1536)         0           tf_op_layer_strided_slice_2[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1537        concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,777\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "time: 1.64 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItoTrDoI_qg2"
      },
      "source": [
        "Load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_RO_P8EcBBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae799a6-4da0-4f63-c19c-2fd4df7d2ccb"
      },
      "source": [
        "print('download model weights')\n",
        "\n",
        "#Previously saved models\n",
        "#bert_model3.h5\n",
        "#https://drive.google.com/file/d/1cmU8bl_JzywEGegw_3iUFzHrS2iYuwj1/view?usp=sharing\n",
        "\n",
        "\n",
        "#Download previously saved bert_model3.h5 which used the same training process\n",
        "!gdown --id 1cmU8bl_JzywEGegw_3iUFzHrS2iYuwj1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download model weights\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cmU8bl_JzywEGegw_3iUFzHrS2iYuwj1\n",
            "To: /content/bert_weights3.h5\n",
            "438MB [00:02, 184MB/s]\n",
            "time: 5.55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LBSBhyO8OOD"
      },
      "source": [
        "Load the weights into model2 from the downloaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyvVge5ymelc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a34d3f-0bb6-4a9f-d25c-8577ad77d10e"
      },
      "source": [
        "print('load model')\n",
        "model2.load_weights('bert_weights3.h5')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load model\n",
            "time: 452 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n3u6sFK8W-z"
      },
      "source": [
        "Predictions for model2 after loading weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_6sBGKUcP7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b7b6cf-b4d6-413f-f271-33faf8cc5f4a"
      },
      "source": [
        "pred2 = model2.predict(test_input,verbose=1)\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1800/1800 [==============================] - 39s 22ms/sample\n",
            "time: 38.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rawLFYBP8k_1"
      },
      "source": [
        "Write the predictions for test dataset into answer.txt with columns id and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLbb7wOx_UuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6654df5-930f-4eec-b845-a3b5b78bfd19"
      },
      "source": [
        "sub=pred2.round()\n",
        "sub=le.inverse_transform(sub.ravel().astype('int16'))\n",
        "sub=pd.DataFrame(sub,columns=['label'])\n",
        "sub=pd.concat([test['id'], sub], axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('answer.txt',sep=',',index=False,header=None)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 19.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}