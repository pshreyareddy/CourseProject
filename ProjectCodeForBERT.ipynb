{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ProjectCodeForBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kDNPpAMV2RBOsX00bXTrJ35wxS6LIVoL",
      "authorship_tag": "ABX9TyMOvPlIphjs/YelHvRAZhp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pshreyareddy/CourseProject/blob/main/ProjectCodeForBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uv6HfU0Boze"
      },
      "source": [
        "Sarcasm Classification In Tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztfX6a25IihD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290931ce-ebfe-4ed0-cd4f-2f076e47679d"
      },
      "source": [
        "# Install TensorFlow packages\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-addons\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 29kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.33.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=87b731db30a50d1d1a5186c219e7347a0ba0450d3b5a003a066df6b15bd3a936\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_N2xH-VY89K"
      },
      "source": [
        "Import Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10VItUvEvppl",
        "outputId": "5641c70c-861e-4750-dd01-8c66a6b27106"
      },
      "source": [
        "import tensorflow as tf; \n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeH4xKYdAFDu",
        "outputId": "a2f6d82a-0d65-46ee-c25b-ece05a0e0257"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmUL_2tlKxOM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import tensorflow packages\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,concatenate,Dense,GlobalAveragePooling1D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymgw8JqtZBww"
      },
      "source": [
        "Read Train Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfy5ui7YK7p7"
      },
      "source": [
        "\n",
        "train = pd.read_json('https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/train.jsonl',lines=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf1pQ4U_ZHTj"
      },
      "source": [
        "Check train data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3F89UFPLFeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b71b0eb6-4272-46e5-8a76-ddfa0b47c5b1"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
              "      <td>[A minor child deserves privacy and should be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
              "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [A minor child deserves privacy and should be ...\n",
              "1  SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n",
              "2  SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n",
              "3  SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n",
              "4  SARCASM  ...  [Man ... y ’ all gone “ both sides ” the apoca...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i7z_zmjBCWH",
        "outputId": "229de871-0388-4a47-b33c-cb91ce54fe42"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label       object\n",
              "response    object\n",
              "context     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD9GO_AiZWCH"
      },
      "source": [
        "Clean the response column in train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trL6cio9LMpT"
      },
      "source": [
        "train['response']=train['response'].str.replace('@USER', \"\") \n",
        "train['response']=train['response'].str.replace('<URL>', \"\") \n",
        "train['response']=train['response'].str.replace('\\d+', '')\n",
        "train['response']=train['response'].str.lower()\n",
        "train['response']=train['response'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHZNtFazZbgp"
      },
      "source": [
        "Check the train data after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1W0r7b7pR_c6",
        "outputId": "fd9fd7d2-43fe-48b1-9c20-73a064e8f589"
      },
      "source": [
        "train['response'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   i dont get this  obviously you do care or you wouldve moved right along  instead you decided to care and troll her '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAr4ENChLQYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c102ea68-e70d-43f2-ae3a-0cb37c020ce1"
      },
      "source": [
        "train['response'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       i dont get this  obviously you do care or y...\n",
              "1      trying to protest about  talking about him a...\n",
              "2       he makes an insane about of money from the ...\n",
              "3      meanwhile trump wont even release his sat sc...\n",
              "4      pretty sure the antilincoln crowd claimed th...\n",
              "Name: response, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgsrQktXZgzs"
      },
      "source": [
        "Convert context(list) into a string and apply the same cleaning logic added on response column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmEd6vJuLTa6"
      },
      "source": [
        "train['context']=train['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "train['context']=train['context'].str.replace('@USER', \"\") \n",
        "train['context']=train['context'].str.replace('<URL', \"\") \n",
        "train['context']=train['context'].str.lower()\n",
        "train['context']=train['context'].str.replace('[^\\w\\s]','')\n",
        "train['context']=train['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w20XN-wXZ8X2"
      },
      "source": [
        "Check the train data after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "nOf-B5EFR18-",
        "outputId": "9aea08b5-6f79-435c-f94b-3593a17e43ba"
      },
      "source": [
        "train['context'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a minor child deserves privacy and should be kept out of politics  pamela karlan  you should be ashamed of your very angry and obviously biased public pandering  and using a child to do it  if your child isnt named barron  bebest melania couldnt care less  fact  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3a2UQTLWPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0493d03-d6dc-4b94-a4e4-23e06772b76c"
      },
      "source": [
        "train['context'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    a minor child deserves privacy and should be k...\n",
              "1      why is he a loser  hes just a press secretar...\n",
              "2    donald j  trump is guilty as charged  the evid...\n",
              "3    jamie raskin tanked doug collins  collins look...\n",
              "4    man  y  all gone  both sides  the apocalypse o...\n",
              "Name: context, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2gEhUXYaN3g"
      },
      "source": [
        "Check the length of train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhGnyAZRLY8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49439d9-15b6-4a1f-fed6-804ee1ac8715"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvbob0xuaTD0"
      },
      "source": [
        "Check the class count of target variable 'label' (Balanced dataset with equal composition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy8ZYwoILctO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e269581-b219-4f6f-be42-0f2ad74dca4d"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(train['label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOT_SARCASM': 2500, 'SARCASM': 2500})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hNYeasPan5K"
      },
      "source": [
        "Label encode class variable to 0 and 1 from  NOT_SARCASM and SARCASM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDPBCmQLfcJ"
      },
      "source": [
        "le=LabelEncoder()\n",
        "train_label=le.fit_transform(train['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zhEdu4FbH9L"
      },
      "source": [
        "Read test data set and check the first 5 rows "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3y24FiDLg0Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aa7da0ed-4280-4c8b-bd2a-a567271ee207"
      },
      "source": [
        "\n",
        "test = pd.read_json('https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/test.jsonl',lines=True)\n",
        "\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
              "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
              "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@USER @USER @USER The irony being that he even...</td>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            context\n",
              "0  twitter_1  ...  [Well now that ’ s problematic AF <URL>, @USER...\n",
              "1  twitter_2  ...  [Last week the Fake News said that a section o...\n",
              "2  twitter_3  ...  [@USER Let ’ s Aplaud Brett When he deserves i...\n",
              "3  twitter_4  ...  [Women generally hate this president . What's ...\n",
              "4  twitter_5  ...  [Dear media Remoaners , you excitedly sharing ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUADHO76BwO1",
        "outputId": "712cb267-e93a-4f6c-8adf-9af866616dd0"
      },
      "source": [
        "test.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          object\n",
              "response    object\n",
              "context     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gBKutXAbUzu"
      },
      "source": [
        "Apply the same cleaning logic for response and context columns in test  as done earlier on train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvD2Gsb9LnCp"
      },
      "source": [
        "test['response']=test['response'].str.replace('@USER', \"\") \n",
        "test['response']=test['response'].str.replace('<URL>', \"\") \n",
        "test['response']=test['response'].str.replace('\\d+', '')\n",
        "test['response']=test['response'].str.lower()\n",
        "test['response']=test['response'].str.replace('[^\\w\\s]','')\n",
        "test['context']=test['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "test['context']=test['context'].str.replace('@USER', \"\") \n",
        "test['context']=test['context'].str.replace('<URL>', \"\") \n",
        "test['context']=test['context'].str.lower()\n",
        "test['context']=test['context'].str.replace('[^\\w\\s]','')\n",
        "test['context']=test['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsWaIP9Ybd9m"
      },
      "source": [
        "Check the test rows after changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "QJzjkKLFSNvF",
        "outputId": "ae4c310b-a332-4023-917e-5cd942c399ca"
      },
      "source": [
        "test['response'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   my  year old  that just finished reading nietzsche and then asked me   ayo papa why these people always trying to cancel someone on twitter  trying to pretend like that makes them better themselves    to which i replied  idk   and he just  cuz hoes mad   im so proud  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZqTh3yc_SUax",
        "outputId": "2624eb4d-8125-4f2d-8a3c-dffbc4acc97d"
      },
      "source": [
        "test['context'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'well now that  s problematic af   my  year old  asked me why they are making fun of native americans    i will take shit that didnt happen for     no  he actually in the gifted program and reads on second grade level    and he knows kansas city is in missouri'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNpSKL8LrIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "72dbe617-8824-4c55-8eba-75e5974ee44f"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>my  year old  that just finished reading ni...</td>\n",
              "      <td>well now that  s problematic af   my  year old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>how many verifiable lies has he told now   d...</td>\n",
              "      <td>last week the fake news said that a section of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>maybe docs just a scrub of a coach  i mean ...</td>\n",
              "      <td>let  s aplaud brett when he deserves it he co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>is just a cover up for the real hate inside ...</td>\n",
              "      <td>women generally hate this president  whats up ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>the irony being that he even has to ask why</td>\n",
              "      <td>dear media remoaners  you excitedly sharing cl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            context\n",
              "0  twitter_1  ...  well now that  s problematic af   my  year old...\n",
              "1  twitter_2  ...  last week the fake news said that a section of...\n",
              "2  twitter_3  ...   let  s aplaud brett when he deserves it he co...\n",
              "3  twitter_4  ...  women generally hate this president  whats up ...\n",
              "4  twitter_5  ...  dear media remoaners  you excitedly sharing cl...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5qtdd7ZblWQ"
      },
      "source": [
        "Check the train rows after changes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC0yfGKeL_hZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "91009918-dc86-4d02-a6ef-c342bfb08bc3"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont get this  obviously you do care or y...</td>\n",
              "      <td>a minor child deserves privacy and should be k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>trying to protest about  talking about him a...</td>\n",
              "      <td>why is he a loser  hes just a press secretar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>he makes an insane about of money from the ...</td>\n",
              "      <td>donald j  trump is guilty as charged  the evid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>meanwhile trump wont even release his sat sc...</td>\n",
              "      <td>jamie raskin tanked doug collins  collins look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>pretty sure the antilincoln crowd claimed th...</td>\n",
              "      <td>man  y  all gone  both sides  the apocalypse o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  a minor child deserves privacy and should be k...\n",
              "1  SARCASM  ...    why is he a loser  hes just a press secretar...\n",
              "2  SARCASM  ...  donald j  trump is guilty as charged  the evid...\n",
              "3  SARCASM  ...  jamie raskin tanked doug collins  collins look...\n",
              "4  SARCASM  ...  man  y  all gone  both sides  the apocalypse o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isO7qfb3btTd"
      },
      "source": [
        "Create a variable traindata from train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy7GjbYpM8SP"
      },
      "source": [
        "traindata = train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPz3I66NqCn",
        "outputId": "f99d4568-7367-4c95-922a-2d2b20a58ed5"
      },
      "source": [
        "len(train_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wimsQCqbyLI"
      },
      "source": [
        "Train Validation Split (To train on 4000 samples and validate on 1000 samples)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyiQgR3fLjHV"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(traindata.drop(labels=['label'], axis=1), train_label, test_size=0.2, random_state=42 ,stratify=train_label)\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKTWWQUbOAyR",
        "outputId": "dea11be7-ba4e-4af1-97f5-6574d39d882c"
      },
      "source": [
        "X_train.shape   #Check the shape of X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mQ9BCQYOPbB",
        "outputId": "658c04f7-ec90-443d-d91c-c139073f3c06"
      },
      "source": [
        "y_train.shape  #Check the shape of y_train\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWDjNnTTOXkV",
        "outputId": "9a5cad9f-733d-417b-cf8c-ef8ae551b93d"
      },
      "source": [
        " X_val.shape   #Check the shape of X_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYV3l550cugd"
      },
      "source": [
        "Check the target variable balance in training and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdASYPQ4acDn",
        "outputId": "8cf701f4-719b-4a6a-bc84-32c786971707"
      },
      "source": [
        "print(Counter(y_val))  \n",
        "print(Counter(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 500, 1: 500})\n",
            "Counter({1: 2000, 0: 2000})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpCBMZ_9wb-Q"
      },
      "source": [
        "Added a keras bert layer using bert uncased L-12_H-768_A-12. Tokenization approach using bert fulltokenizer followed as per usage in below tfhub link\n",
        "\n",
        "https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w5IQ1yaCJ5l",
        "outputId": "07d4fbc7-a64e-47f9-8d9c-2442b849e1b8"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow_hub' from '/usr/local/lib/python3.6/dist-packages/tensorflow_hub/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKpdfByIMMAU"
      },
      "source": [
        "\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "595wfOWl8jcP"
      },
      "source": [
        "\n",
        "Download and import bert tokenization file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPUMH0SbNNax"
      },
      "source": [
        "#!wget --quiet https://raw.githubusercontent.com/google-research/BERT/master/tokenization.py\n",
        "#!cp \"/content/drive/MyDrive/tokenization.py\"\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbeqeDuNMUfX"
      },
      "source": [
        "import tokenization\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcBJa14Lwr3K"
      },
      "source": [
        "Encoding function to separate the text into tokens,masks and segments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozqUNSBMTLh"
      },
      "source": [
        "def encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJbN9glMXG8"
      },
      "source": [
        " max_len=256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPCW5GNGOhVG"
      },
      "source": [
        "val_response = encode(X_val.response, tokenizer, max_len=max_len)\n",
        "val_context = encode(X_val.context, tokenizer, max_len=max_len)\n",
        "val_labels=y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCMviZPVMZde"
      },
      "source": [
        "train_response = encode(X_train.response, tokenizer, max_len=max_len)\n",
        "train_context = encode(X_train.context, tokenizer, max_len=max_len)\n",
        "train_labels=y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9TJBJ8McXB"
      },
      "source": [
        "test_response = encode(test.response, tokenizer, max_len=max_len)\n",
        "test_context = encode(test.context, tokenizer, max_len=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmXxWlaRMeya"
      },
      "source": [
        "test_input=[test_context[0],test_context[1],test_context[2],test_response[0],test_response[1],test_response[2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPJG2p4uvH-9"
      },
      "source": [
        "Helper functions for Evaluation metrics like recall,precision and f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So_tGeaJQRdH"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFYjwXSmd4Xy"
      },
      "source": [
        "Build model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiXHWqnMlQG"
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    context_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_word_ids\")\n",
        "    context_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"context_mask\")\n",
        "    context_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"context_seg_ids\")\n",
        "    context_pooled_output , context_seq_output = bert_layer([context_word_ids, context_mask, context_seg_ids])\n",
        "    context_clf_output = context_seq_output[:, 0, :]\n",
        "\n",
        "\n",
        "    reponse_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_word_ids\")\n",
        "    reponse_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_mask\")\n",
        "    reponse_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_seg_ids\")\n",
        "    response_pooled_output , reponse_seq_output = bert_layer([reponse_word_ids, reponse_mask, reponse_seg_ids])\n",
        "    reponse_clf_output = reponse_seq_output[:, 0, :]\n",
        "\n",
        "\n",
        "    conclayer=concatenate([context_clf_output,reponse_clf_output])\n",
        "    out = Dense(1, activation='sigmoid')(conclayer)\n",
        "    \n",
        "    model = Model(inputs=[context_word_ids, context_mask, context_seg_ids,reponse_word_ids,reponse_mask,reponse_seg_ids], outputs=out)\n",
        "    model.compile(Adam(1e-6), loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "    return model\n",
        "\n",
        "# context_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_word_ids\")\n",
        "# context_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"context_mask\")\n",
        "# context_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"context_seg_ids\")\n",
        "# context_pooled_output , context_seq_output = bert_layer([context_word_ids, context_mask, context_seg_ids])\n",
        "# context_clf_output = context_seq_output[:, 0, :]\n",
        "\n",
        "\n",
        "# reponse_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_word_ids\")\n",
        "# reponse_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_mask\")\n",
        "# reponse_seg_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_seg_ids\")\n",
        "# response_pooled_output , reponse_seq_output = bert_layer([reponse_word_ids, reponse_mask, reponse_seg_ids])\n",
        "# reponse_clf_output = reponse_seq_output[:, 0, :]\n",
        "\n",
        "\n",
        "# conclayer=concatenate([context_clf_output,reponse_clf_output])\n",
        "# out = Dense(1, activation='sigmoid')(conclayer)\n",
        "    \n",
        "# model = Model(inputs=[context_word_ids, context_mask, context_seg_ids,reponse_word_ids,reponse_mask,reponse_seg_ids], outputs=out)\n",
        "# model.compile(Adam(1e-6), loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouDt9OpzHBRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3636fed5-eb4c-46bc-bea1-a1ec47a743e8"
      },
      "source": [
        "\n",
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "contex_word_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      [(None, 768), (None, 109482241   contex_word_ids[0][0]            \n",
            "                                                                 context_mask[0][0]               \n",
            "                                                                 context_seg_ids[0][0]            \n",
            "                                                                 reponse_word_ids[0][0]           \n",
            "                                                                 reponse_mask[0][0]               \n",
            "                                                                 reponse_seg_ids[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_8 (Te [(None, 768)]        0           keras_layer_3[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_9 (Te [(None, 768)]        0           keras_layer_3[1][1]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1536)         0           tf_op_layer_strided_slice_8[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_9[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            1537        concatenate_4[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,777\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jXoYzrLd_FI"
      },
      "source": [
        "Set train_input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP2rqQdeMn7B"
      },
      "source": [
        "train_input=[train_context[0],train_context[1],train_context[2],train_response[0],train_response[1],train_response[2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kH5hXOU547s"
      },
      "source": [
        "Set val_input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnPSQ4UPPVL2"
      },
      "source": [
        "val_input=[val_context[0],val_context[1],val_context[2],val_response[0],val_response[1],val_response[2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H53q_MYh9zPD"
      },
      "source": [
        "Training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIa8suJBPnhX",
        "outputId": "a236b805-3c0b-4ba5-893d-d5ee11a7a8f3"
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_input, y_train,\n",
        "    validation_data =(val_input,y_val),\n",
        "    epochs=3,\n",
        "    batch_size=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/3\n",
            "4000/4000 [==============================] - 337s 84ms/sample - loss: 0.5813 - acc: 0.6815 - f1_m: 0.5717 - precision_m: 0.5910 - recall_m: 0.6128 - val_loss: 0.4926 - val_acc: 0.7600 - val_f1_m: 0.6401 - val_precision_m: 0.6572 - val_recall_m: 0.6781\n",
            "Epoch 2/3\n",
            "4000/4000 [==============================] - 314s 79ms/sample - loss: 0.4332 - acc: 0.7987 - f1_m: 0.6909 - precision_m: 0.6939 - recall_m: 0.7348 - val_loss: 0.4491 - val_acc: 0.7880 - val_f1_m: 0.6716 - val_precision_m: 0.6712 - val_recall_m: 0.7231\n",
            "Epoch 3/3\n",
            "4000/4000 [==============================] - 314s 79ms/sample - loss: 0.3316 - acc: 0.8685 - f1_m: 0.7633 - precision_m: 0.7645 - recall_m: 0.7969 - val_loss: 0.4332 - val_acc: 0.7970 - val_f1_m: 0.6594 - val_precision_m: 0.6722 - val_recall_m: 0.6946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mRDehi981H"
      },
      "source": [
        "Predictions for test_input for the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ayRkJGMxpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a160abc-07b6-487b-a27e-d4293b5e8bc4"
      },
      "source": [
        "pred=model.predict(test_input,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1800/1800 [==============================] - 39s 22ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqzRrUPH-Bmz"
      },
      "source": [
        "Write the predictions for test dataset into answer.txt with columns id and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5oatnx-M3LV"
      },
      "source": [
        "\n",
        "sub=pred.round()\n",
        "sub=le.inverse_transform(sub.ravel().astype('int16'))\n",
        "sub=pd.DataFrame(sub,columns=['label'])\n",
        "sub=pd.concat([test['id'], sub], axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('answer.txt',sep=',',index=False,header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCjEO6Mk-_Ci"
      },
      "source": [
        "Save model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-fkc9Xq-8xx"
      },
      "source": [
        "model_save_name = 'bert_weights1.h5'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w-AsWVZ-Qxu"
      },
      "source": [
        "Loading model weights from already generated saved model weights file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2xuVMO1-d1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad7be63-b28b-40a6-95b1-db7bea67ad24"
      },
      "source": [
        "model2 = build_model(bert_layer, max_len=max_len)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "contex_word_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "context_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_word_ids (InputLayer)   [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_mask (InputLayer)       [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reponse_seg_ids (InputLayer)    [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      [(None, 768), (None, 109482241   contex_word_ids[0][0]            \n",
            "                                                                 context_mask[0][0]               \n",
            "                                                                 context_seg_ids[0][0]            \n",
            "                                                                 reponse_word_ids[0][0]           \n",
            "                                                                 reponse_mask[0][0]               \n",
            "                                                                 reponse_seg_ids[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_12 (T [(None, 768)]        0           keras_layer_3[4][1]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_13 (T [(None, 768)]        0           keras_layer_3[5][1]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1536)         0           tf_op_layer_strided_slice_12[0][0\n",
            "                                                                 tf_op_layer_strided_slice_13[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            1537        concatenate_6[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,777\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_RO_P8EcBBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384cedc9-363a-4d1a-a95c-46170d15f3b3"
      },
      "source": [
        "print('load model')\n",
        "# model2.load_weights('/content/drive/My Drive/bert_weights.h5')\n",
        "\n",
        "# https://drive.google.com/file/d/1hWyGrsE69dCJBK4HI-VFJql7PDiEG2LA/edit\n",
        "\n",
        "#https://drive.google.com/file/d/1bHc2hz5rJ7eyYIZqPtBhgVXMy1fsMCc_/view?usp=sharing\n",
        "\n",
        "#!gdown --id 1hWyGrsE69dCJBK4HI-VFJql7PDiEG2LA\n",
        "\n",
        "!gdown --id 1bHc2hz5rJ7eyYIZqPtBhgVXMy1fsMCc_\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load model\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bHc2hz5rJ7eyYIZqPtBhgVXMy1fsMCc_\n",
            "To: /content/bert_weights1.h5\n",
            "438MB [00:01, 247MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyvVge5ymelc"
      },
      "source": [
        "model2.load_weights('bert_weights1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_6sBGKUcP7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf180ac-996a-4d79-bd58-17677bf211a7"
      },
      "source": [
        "pred2 = model2.predict(test_input,verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1800/1800 [==============================] - 38s 21ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLbb7wOx_UuF"
      },
      "source": [
        "sub=pred2.round()\n",
        "sub=le.inverse_transform(sub.ravel().astype('int16'))\n",
        "sub=pd.DataFrame(sub,columns=['label'])\n",
        "sub=pd.concat([test['id'], sub], axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('answer.txt',sep=',',index=False,header=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}